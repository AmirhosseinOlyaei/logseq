- [[Group-work 1: The Craigslist Rebuild]]
	- TODO [A pdf slide deck](https://visme.co/blog/slide-deck/) of the work you just did. [Here's a template](https://github.com/msimbo/markdown-templates/blob/main/hackmd-demo-presentation.md) ([looks like this](https://hackmd.io/@deletosh/msb-tpl-slide#/)) if you want to write it with markdown, [here's a quick guide](https://hackmd.io/c/tutorials/%2Fs%2Fhow-to-create-slide-deck).
- [[Project 5: CreativePainter.io]]
	- Steps to solve the problem:
		- 1. Through JS
		  2. Through React.js
		- create a repo. cp-js
		- issues.
			- research and test open.ai api.
				- paste link and codes from note in comment.
			- design a pure html and css version.
				- screenshot and paste in comment
			- allow user to generate an ai image from prompt
				- be sure the api works in js
				- be sure that i can test with other cats outside
				- i need to make prompt dynamic
				- response from api: paste the result code
			- allow user to see and use my app on vercel
		- open.ai. doc. image generation. Usage. node.js. copy and paste in a note. url. copy and paste in note.
		- cd msimbo-projects. git clone the repo. cd cp-js. git checkout -b feature/apiresearch
		- create a README.md file.
		- http request. apenai.http. create an http request. paste the code there. run. it converts to webstorm.
		- api key. login. generate. copy the code. paste after Bearer in http file. run. copy generated url and test in browser.
		- in front of prompt. change to a dog running. test
		- change prompt to civil right leaders in America.
		- gitignore idea
		- git rm -rf .idea . deletes from git but not the local. if we forget to ignore idea.
		- push to github. close issue 1
		- git branch -b feature/html-css-2, touch index.html, webstorm .
		- yarn add -D live-server
		- add tailwind dev cdn. design html and css. push to git
		- git checkout -b main, merge branches to main and set main as default on github
		- `<script src="app.js></script>` at the end of html
		- creat app.js
			- console.log("this works"); open console in live server browser
			- 1. get all the html DOM
			  2. listen to the even on the prompt input
			  2a. on the blur event, call the image generate API
			  2b. show the image in the browser
		- api key exist in local and production in vercel
			- create a config.js
				- const config = { API_KEY: "key"}
				- export default config;
			- ignore config.js
			- `import config from "./config.js";`
			- Bearer ${config.API_KEY}
			- `<script src="config.js" type="modules"></script>` in html
			- vercel, settings, general, build, cd cp-js && echo -e " const ...."
			- `echo -e "const config = { API_KEY: 'XXXXXXXXX' }; export default config;" > config.js`
			- output directory .
	- app.js code does the following:
		- Retrieves the `search-box` and `images` elements from the DOM.
		- Adds an event listener to the `search-box` element that triggers when the input field loses focus (i.e., the user clicks away from it).
		- When the event is triggered, the code sends a POST request to OpenAI's image generation API with the user's input as the prompt. The `model` parameter specifies the model to use for image generation, and `num_images` specifies the number of images to generate (in this case, just one). `size` specifies the size of the generated image, and `response_format` specifies the format of the API response (in this case, a URL).
		- The response from the API is parsed as JSON, and the URL of the generated image is extracted.
		- A new `img` element is created in the DOM, and the `src` attribute is set to the URL of the generated image.
		- The `img` element is appended to the `images` element, and the generated image is displayed in the browser.